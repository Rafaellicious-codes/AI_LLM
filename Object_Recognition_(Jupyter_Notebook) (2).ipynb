{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlDizm4JyfiL"
      },
      "source": [
        "## Near State-of-the-Art results at Object Recognition\n",
        "\n",
        "In this project, we will be deploying a convolutional neural network (CNN) for object recognition. More specifically, we will be using the All-CNN network published in the 2015 ICLR paper, \"Striving For Simplicity: The All Convolutional Net\".  This paper can be found at the following link:\n",
        "\n",
        "https://arxiv.org/pdf/1412.6806.pdf\n",
        "\n",
        "This convolutional neural network obtained state-of-the-art performance at object recognition on the CIFAR-10 image dataset in 2015. We will build this model using Keras, a high-level neural network application programming interface (API) that supports both Theano and Tensorflow backends. You can use either backend; however, I will be using Theano.  \n",
        "\n",
        "In this project:\n",
        "* Import datasets from Keras\n",
        "* Use one-hot vectors for categorical labels\n",
        "* Addlayers to a Keras model\n",
        "* Load pre-trained weights\n",
        "* Make predictions using a trained Keras model\n",
        "\n",
        "The dataset we will be using is the CIFAR-10 dataset, which consists of 60,000 32x32 color images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "### 1. Loading the Data\n",
        "\n",
        "Let's dive right in! In these first few cells, we will import necessary packages, load the dataset, and plot some example images."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install np_utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEDtCwK-zD6B",
        "outputId": "ce5be76c-9190-4830-be46-8f978d85e054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting np_utils\n",
            "  Downloading np_utils-0.6.0.tar.gz (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from np_utils) (2.0.2)\n",
            "Building wheels for collected packages: np_utils\n",
            "  Building wheel for np_utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for np_utils: filename=np_utils-0.6.0-py3-none-any.whl size=56437 sha256=8b870b2db02b90a8cedbff7fd508134230d836a8b23f375b1b91050a58b6cc09\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/0d/33/eaa4dcda5799bcbb51733c0744970d10edb4b9add4f41beb43\n",
            "Successfully built np_utils\n",
            "Installing collected packages: np_utils\n",
            "Successfully installed np_utils-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras matplotlib numpy\n"
      ],
      "metadata": {
        "id": "bi_i_UOxyn-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqZKNaqvyfiP"
      },
      "outputs": [],
      "source": [
        "# Load necessary packages\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import PIL\n",
        "\n",
        "from keras import utils                                   # tools for creating one-hot encoding\n",
        "from keras.models import Sequential                       # Type of model we wish to use\n",
        "from keras.layers import Dense, Dropout, Activation       # Types of layers we wish to use\n",
        "from keras.datasets import cifar10\n",
        "#from keras.utils import np_utils\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz7vd4RryfiR"
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UM3Zufb6yfiS"
      },
      "outputs": [],
      "source": [
        "# Lets determine the dataset characteristics\n",
        "print('Training Images: {}'.format(X_train.shape))\n",
        "print('Testing Images: {}'.format(X_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezogHk0yyfiS"
      },
      "outputs": [],
      "source": [
        "# Now for a single image\n",
        "print(X_train[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH_g6793yfiT"
      },
      "outputs": [],
      "source": [
        "# create a grid of 3x3 images\n",
        "for i in range(0,9):\n",
        "    plt.subplot(330 + 1 + i)\n",
        "    # Corrected the transpose order to (1, 2, 0)\n",
        "    img = X_train[i].transpose([1,0,2])\n",
        "    plt.imshow(img)\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_E2-TSDyfiU"
      },
      "source": [
        "### 2. Preprocessing the dataset\n",
        "\n",
        "First things first, we need to preprocess the dataset so the images and labels are in a form that Keras can ingest. To start, we'll define a NumPy seed for reproducibility, then normalize the images.\n",
        "\n",
        "Furthermore, we will also convert our class labels to one-hot vectors.  This is a standard output format for neural networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmI5Zm0YyfiV"
      },
      "outputs": [],
      "source": [
        "# Building a convolutional neural network for object recognition on CIFAR-10\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 6\n",
        "np.random.seed(seed)\n",
        "\n",
        "# load the data\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# normalize the inputs from 0-255 to 0.0-1.0\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFbAs0TByfiW"
      },
      "outputs": [],
      "source": [
        "# class labels shape\n",
        "print(y_train.shape)\n",
        "print(y_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm6yG5ylyfiX"
      },
      "source": [
        "The class labels are a single integer value (0-9).  What we really want is a one-hot vector of length ten.  For example, the class label of 6 should be denoted [0, 0, 0, 0, 0, 0, 1, 0, 0, 0].  We can accomplish this using the np_utils.to_categorical() function."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow import keras # Import keras if not already imported\n",
        "from keras.utils import to_categorical # Import to_categorical\n",
        "\n",
        "Y_train = to_categorical(y_train)\n",
        "Y_test = to_categorical(y_test)\n",
        "num_classes = Y_test.shape[1]\n",
        "\n",
        "print(Y_train.shape)\n",
        "print(Y_train[0])"
      ],
      "metadata": {
        "id": "OokHDjWe0WQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfq4pYseyfiX"
      },
      "source": [
        "### 3. Building the All-CNN\n",
        "\n",
        "Using the paper as a reference, we can implement the All-CNN network in Keras.  Keras models are built by simply adding layers, one after another.\n",
        "\n",
        "To make things easier for us later, we will wrap this model in a function, which will allow us to quickly and neatly generate the model later on in the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGM126llyfiY"
      },
      "outputs": [],
      "source": [
        "# start building the model - import necessary layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Activation, Conv2D, GlobalAveragePooling2D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "def allcnn(weights=None):\n",
        "    # define model type - Sequential\n",
        "    model = Sequential()\n",
        "\n",
        "    # add model layers - Convolution2D, Activation, Dropout\n",
        "    model.add(Conv2D(96, (3, 3), padding = 'same', input_shape=(3, 32, 32)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(96, (3, 3), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(96, (3, 3), padding = 'same', strides = (2,2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(192, (3, 3), padding = 'same', strides = (2,2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(192, (1, 1), padding = 'valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(10, (1, 1), padding = 'valid'))\n",
        "\n",
        "    # add GlobalAveragePooling2D layer with Softmax activation\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # load the weights\n",
        "    if weights:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    # return model\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPBzmxBayfiY"
      },
      "source": [
        "### 4. Defining Parameters and Training the Model\n",
        "\n",
        "We're all set! We are ready to start training our network.  In the following cells, we will define our hyper parameters, such as learning rate and momentum, define an optimizer, compile the model, and fit the model to the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoaQRqzqyfiY"
      },
      "outputs": [],
      "source": [
        "# define hyper parameters\n",
        "learning_rate = 0.01\n",
        "weight_decay = 1e-6\n",
        "momentum = 0.9\n",
        "\n",
        "# build model\n",
        "model = allcnn()\n",
        "\n",
        "# define optimizer and compile model\n",
        "# chanfed kera kr argument with the learning rate argument\n",
        "sgd = SGD(learning_rate=learning_rate, decay=weight_decay, momentum=momentum, nesterov=True) # Changed 'lr' to 'learning_rate'\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# print model summary\n",
        "print (model.summary())\n",
        "\n",
        "# define additional training parameters\n",
        "epochs = 350\n",
        "batch_size = 32\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, batch_size=batch_size, verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kfPdjtLyfiZ"
      },
      "source": [
        "### 5. Woah, that's a long time...\n",
        "\n",
        "Uh oh. It's apparent that training this deep convolutional neural network is going to take a long time, which is not surprising considering the network has about 1.3 million parameters. Updating this many parameters takes a considerable amount of time; unless, of course, you are using a Graphics Processing Unit (GPU). This is a good time for a quick lesson on the differences between CPUs and GPUs.  \n",
        "\n",
        "The **central processing unit (CPU)** is often called the brains of the PC because it handles the majority of necessary computations. All computers have a CPU and this is what Keras and Theano automatically utilize.\n",
        "\n",
        "The **graphics processing unit (GPU)** is in charge of image rendering.  The most advanced GPUs were originally designed for gamers; however, GPU-accelerated computing, the use of a GPU together with a CPU to accelarate deep learing, analytics, and engineering applications, has become increasingly common.  In fact, the training of deep neural networks is not realistic without them.\n",
        "\n",
        "The most common GPUs for deep learning are produced by NVIDIA.  Furthermore, the NVIDIA Deep Learning SDK provides high-performance tools and libraries to power GPU-accelerated machine learning applications. An alternative would be an AMD GPU in combination with the OpenCL libraries; however, these libraries have fewer active users and less support than the NVIDIA libraries.\n",
        "\n",
        "If your computer has an NVIDIA GPU, installing the CUDA Drivers and CUDA Tookit from NVIDIA will allow Theano and Keras to utilize GPU-accelerated computing. The original paper mentions that it took approximately 10 hours to train the All-CNN network for 350 epochs using a modern GPU, which is considerably faster (several orders of magnitude) than it would take to train on CPU.\n",
        "\n",
        "If you haven't already, stop the cell above. In the following cells, we'll save some time by loading pre-trained weights for the All-CNN network. Using these weights, we can evaluate the performance of the All-CNN network on the testing dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# start building the model - import necessary layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Activation, Conv2D, GlobalAveragePooling2D\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "def allcnn(weights=None):\n",
        "    # define model type - Sequential\n",
        "    model = Sequential()\n",
        "\n",
        "    # add model layers - Convolution2D, Activation, Dropout\n",
        "    # Changed input_shape to (32, 32, 3) to match the expected shape of the pretrained weights\n",
        "    model.add(Conv2D(96, (3, 3), padding = 'same', input_shape=(32, 32, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(96, (3, 3), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(96, (3, 3), padding = 'same', strides = (2,2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(192, (3, 3), padding = 'same', strides = (2,2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(192, (1, 1), padding = 'valid'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(10, (1, 1), padding = 'valid'))\n",
        "\n",
        "    # add GlobalAveragePooling2D layer with Softmax activation\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # load the weights\n",
        "    if weights:\n",
        "        model.load_weights(weights)\n",
        "\n",
        "    # return model\n",
        "    return model"
      ],
      "metadata": {
        "id": "N_bZWpJ-7oQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0Dyc1T4yfiZ"
      },
      "source": [
        "### 6. Making Predictions\n",
        "\n",
        "Using the pretrained weights, we were able to achieve an accuracy of nearly 90 percent! Let's leverage this network to make some predictions. To start, we will generate a dictionary of class labels and names by referencing the website for the CIFAR-10 dataset:\n",
        "\n",
        "https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "\n",
        "Next, we'll make predictions on nine images and compare the results to the ground-truth labels.  Furthermore, we will plot the images for visual reference, this is object recognition after all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjOq5gEcyfiZ",
        "outputId": "acc605dc-a9ea-40c7-8869-dd43849c2357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456ms/step\n"
          ]
        }
      ],
      "source": [
        "# make dictionary of class labels and names\n",
        "classes = range(0,10)\n",
        "\n",
        "names = ['airplane',\n",
        "        'automobile',\n",
        "        'bird',\n",
        "        'cat',\n",
        "        'deer',\n",
        "        'dog',\n",
        "        'frog',\n",
        "        'horse',\n",
        "        'ship',\n",
        "        'truck']\n",
        "\n",
        "# zip the names and classes to make a dictionary of class_labels\n",
        "class_labels = dict(zip(classes, names))\n",
        "\n",
        "# generate batch of 9 images to predict\n",
        "batch = X_test[100:109]\n",
        "labels = np.argmax(Y_test[100:109],axis=-1)\n",
        "\n",
        "# make predictions\n",
        "predictions = model.predict(batch, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgWEOQxfyfia"
      },
      "outputs": [],
      "source": [
        "# print our predictions\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0bjadMQyfia"
      },
      "outputs": [],
      "source": [
        "# these are individual class probabilities, should sum to 1.0 (100%)\n",
        "for image in predictions:\n",
        "    print(np.sum(image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mwejJM3yfia"
      },
      "outputs": [],
      "source": [
        "# use np.argmax() to convert class probabilities to class labels\n",
        "class_result = np.argmax(predictions,axis=-1)\n",
        "print(class_result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a grid of 3x3 images\n",
        "fig, axs = plt.subplots(3, 3, figsize = (15, 6))\n",
        "fig.subplots_adjust(hspace = 1)\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, img in enumerate(batch):\n",
        "\n",
        "    # determine label for each prediction, set title\n",
        "    for key, value in class_labels.items():\n",
        "        if class_result[i] == key:\n",
        "            title = 'Prediction: {}\\nActual: {}'.format(class_labels[key], class_labels[labels[i]])\n",
        "            axs[i].set_title(title)\n",
        "            axs[i].axes.get_xaxis().set_visible(False)\n",
        "            axs[i].axes.get_yaxis().set_visible(False)\n",
        "\n",
        "    # plot the image\n",
        "    # The original transpose was [1,2,0], changed to [1, 0, 2] to keep the color channel as the last dimension\n",
        "    axs[i].imshow(img.transpose([1, 0, 2])) # or, img.transpose(1, 0, 2) for numpy >= 1.18\n",
        "\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_c9y0sxJ8LzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjoOrruryfia"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}