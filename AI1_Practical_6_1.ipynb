{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qav_UO1VZkB"
      },
      "outputs": [],
      "source": [
        "# let's install the packages we need first\n",
        "%%capture\n",
        "!pip install openai langchain-openai langchain-community langchain-core"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXUwB7HUwLlL"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2f6paXo-w_z"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsSsTnF6wPn2"
      },
      "outputs": [],
      "source": [
        "# Set OpenAI API Key for today\n",
        "os.environ[\"OPENAI_API_KEY\"] = ***insert open ai API key here ***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBMWtP5ZyRzV"
      },
      "source": [
        "**LangChain** is a framework designed to build applications powered by large language models (LLMs). One of its core components is the *Chain*, which represents a structured sequence of operations where inputs are processed through a series of steps to generate meaningful outputs.\n",
        "\n",
        "**What is a Chain?**\n",
        "\n",
        "A *Chain* in LangChain is a modular pipeline that takes an input (e.g., a user query), processes it through different components (such as prompt templates, LLM calls, or memory storage), and produces an output. This structure allows for flexibility, composability, and control when interacting with LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SDZnk4Ptxp3"
      },
      "source": [
        "First you define a Prompt template. This is a generic mechanism to have a Prompt with variables, like the one you used in the previous practical to import a document. In this simple example we define the Prompt in the function itself rather than through a f\"\"\" syntax. If you want to do it through a f\"\"\" syntax:\n",
        "\n",
        "`template = f\"\"\" this is a question about {var} \"\"\"`\n",
        "\n",
        " you need to instantiate the variables {vars} before activating the template cell, and then call the function in this way:\n",
        "\n",
        "`prompt = PromptTemplate.from_template(template)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOdSDiIYwX9d"
      },
      "outputs": [],
      "source": [
        "# Define a prompt template with a variable\n",
        "prompt = PromptTemplate.from_template(\"What is the capital of {country}?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvsuF8oAvEDF"
      },
      "source": [
        "Then you define the LLM parameter for the Chain by choosing the model. ChatOpenAI is a LanghChain function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "faep6L1Zww-g"
      },
      "outputs": [],
      "source": [
        "# Load an LLM (e.g., OpenAI's GPT-4)\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUM_5HMEvP8o"
      },
      "source": [
        "Nex you create the `chain` using the LangChain function `LLMChain`. Note that in future versions this will be deprecated but this one is the simplest one for a quick intriduction to the concept."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpvOqBJMwzT1"
      },
      "outputs": [],
      "source": [
        "# Create the chain\n",
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASqFYlv3vkYF"
      },
      "source": [
        "Finally, you 'run' the chain. You only need to input the variable which was in the Prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATGIcB1mw12z",
        "outputId": "8addff9b-a07a-4b8e-93df-1b7cb58741aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'country': 'Italy', 'text': 'The capital of Italy is Rome.'}\n"
          ]
        }
      ],
      "source": [
        "# Run the chain\n",
        "response = chain.invoke({\"country\": \"Italy\"})\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlOIMW3_4tkL"
      },
      "source": [
        "# Prompt Routing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgjPvaD22KbI"
      },
      "source": [
        "One way to deal with complex queries is to defi**N**e specialised Prompts. If you want to write a generic Prompt covering all topics the prompt might get lengthy and complex but the precision of responses might also vary. By directing prompts to models specialized in a given domain (e.g., legal, medical, technical), responses become more precise and contextually appropriate. You can also define styles for responding depending on the query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGSJ5PoS_ZYd"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.router.multi_prompt import MultiPromptChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6w6wUq1y-MK"
      },
      "source": [
        "Here you define templates for all separate prompts you need. You also need to define a generic Prompt template when none of the specialised ones get recognised."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuAH7H77_kxh"
      },
      "outputs": [],
      "source": [
        "prompt_1_template = \"\"\"\n",
        "You are an expert programmer. Generate concise but readable code. \\\n",
        "Unless otherwise specified, you should only answer in Python. \\\n",
        "Produce code as requested:\n",
        "\n",
        "{input}\n",
        "\"\"\"\n",
        "\n",
        "prompt_2_template = \"\"\"\n",
        "You are an expert on digital marketing.\n",
        "You will answer in rhymes:\n",
        "{input}\n",
        "\"\"\"\n",
        "\n",
        "# Default prompt template (this could be something like a general FAQ)\n",
        "default_prompt_template = \"\"\"\n",
        "Please provide a general answer to the following query:\n",
        "\n",
        "{input}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPpkgI6Bzmh2"
      },
      "source": [
        "You then define Prompt information that will be used for Prompt selection. Here the query will be matched to the Prompt's \"name\" field as the main topic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-R8HsG__6ds"
      },
      "outputs": [],
      "source": [
        "prompt_infos = [\n",
        "    {\n",
        "        \"name\": \"programming\",\n",
        "        \"description\": \"prompt for code generation\",\n",
        "        \"prompt_template\": prompt_1_template,\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"marketing\",\n",
        "        \"description\": \"prompt for marketing advice\",\n",
        "        \"prompt_template\": prompt_2_template,\n",
        "    },\n",
        "]\n",
        "\n",
        "# Add default prompt as a fallback option\n",
        "default_prompt_info = {\n",
        "    \"name\": \"default\",\n",
        "    \"description\": \"default general prompt\",\n",
        "    \"prompt_template\": default_prompt_template,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMKtbj8_0-0n"
      },
      "source": [
        "Then, first select the relevant Prompt (you get the default Prompt if none can be matched to the query). The **chain** is created with another LangChain function, which is `MultiPromptChain.from_prompts`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNpPIgx6EaEa"
      },
      "outputs": [],
      "source": [
        "# Define a default prompt\n",
        "default_prompt = PromptTemplate.from_template(default_prompt_template)\n",
        "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fcNrLzgFYuh"
      },
      "outputs": [],
      "source": [
        "# Create the MultiPromptChain with a default chain\n",
        "chain = MultiPromptChain.from_prompts(llm, prompt_infos, default_chain=default_chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItfU01KD01wz"
      },
      "source": [
        "Choose ONE of the queries below. Then you can write your own and experiment. You can also modify the similarity threshold for embeddings-based semantic similarity in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX5WO7N1Ecxp"
      },
      "outputs": [],
      "source": [
        "query = \"How do I code a dictionary  search?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkcrzKYqBiXn"
      },
      "outputs": [],
      "source": [
        "query = \"How do I develop an inbound strategy for my new product?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeedJ2BNF3Hp"
      },
      "outputs": [],
      "source": [
        "query = \"What is the capital of South Africa?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tIHEZBY1VrY"
      },
      "source": [
        "You can run the chain with the query as input. NOTE: there are different ways to run a LangChain chain (`.run` , `.invoke`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N2RGPNxBfl_",
        "outputId": "3d8fa51d-29b5-455b-857f-4d5816be8120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To craft your inbound marketing with flair,  \n",
            "Start with a strategy, make sure you care.  \n",
            "First define your buyer, know them well,  \n",
            "Create personas, their needs you must tell.  \n",
            "\n",
            "Next, produce content—blogs, video, or guides,  \n",
            "That answers their questions and helps them decide.  \n",
            "Optimize for search, let keywords be your friend,  \n",
            "With SEO tactics, your reach will extend.  \n",
            "\n",
            "Engage on social, be vibrant and bright,  \n",
            "Share posts that resonate, bring delight.  \n",
            "Email campaigns should nurture the lead,  \n",
            "Personalized messages plant the right seed.  \n",
            "\n",
            "Track all your metrics, see what aligns,  \n",
            "Refine your approach as your data shines.  \n",
            "With patience and care, as you steadily grow,  \n",
            "Your inbound strategy will steal the show!\n"
          ]
        }
      ],
      "source": [
        "# You can now pass the query to the chain and get the response\n",
        "response = chain.run(input=query)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGQkS5E_GbRb"
      },
      "source": [
        "# LangGraph Version (actual LangChain tutorial, modified for Prompts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a864796-ec89-4962-87b3-633f90687e1d"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -qU langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADXZLZuTG8wO"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from typing import Literal\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import END, START, StateGraph\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBM1T0ZdHALi"
      },
      "outputs": [],
      "source": [
        "# Define the prompts we will route to\n",
        "prompt_1 = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"\"\"You are an expert programmer. Generate concise but readable code. \\\n",
        "         Unless otherwise specified, you should only answer in Javascript. \\\n",
        "         Produce code as requested:\"\"\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "prompt_2 = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"\"\"You are an expert on marketing. \\\n",
        "         You will answer in rhymes:\"\"\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf1edd2b-7592-47f4-ba8d-94a56742a585"
      },
      "outputs": [],
      "source": [
        "# Construct the chains we will route to. These format the input query\n",
        "# into the respective prompt, run it through a chat model, and cast\n",
        "# the result to a string.\n",
        "chain_1 = prompt_1 | llm | StrOutputParser()\n",
        "chain_2 = prompt_2 | llm | StrOutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7m3x-XhHUG8"
      },
      "outputs": [],
      "source": [
        "# Next: define the chain that selects which branch to route to.\n",
        "# Here we will take advantage of tool-calling features to force\n",
        "# the output to select one of two desired branches.\n",
        "route_system = \"Route the user's query to either prompt.\"\n",
        "route_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", route_system),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWtm2RnfHS1f"
      },
      "outputs": [],
      "source": [
        "# Define schema for output:\n",
        "class RouteQuery(TypedDict):\n",
        "    \"\"\"Route query to destination expert.\"\"\"\n",
        "\n",
        "    destination: Literal[\"programming\", \"marketing\"]\n",
        "\n",
        "\n",
        "route_chain = route_prompt | llm.with_structured_output(RouteQuery)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1Qn22lxHNiD"
      },
      "outputs": [],
      "source": [
        "# For LangGraph, we will define the state of the graph to hold the query,\n",
        "# destination, and final answer.\n",
        "class State(TypedDict):\n",
        "    query: str\n",
        "    destination: RouteQuery\n",
        "    answer: str\n",
        "\n",
        "\n",
        "# We define functions for each node, including routing the query:\n",
        "async def route_query(state: State, config: RunnableConfig):\n",
        "    destination = await route_chain.ainvoke(state[\"query\"], config)\n",
        "    return {\"destination\": destination}\n",
        "\n",
        "\n",
        "# And one node for each prompt\n",
        "async def prompt_1(state: State, config: RunnableConfig):\n",
        "    return {\"answer\": await chain_1.ainvoke(state[\"query\"], config)}\n",
        "\n",
        "\n",
        "async def prompt_2(state: State, config: RunnableConfig):\n",
        "    return {\"answer\": await chain_2.ainvoke(state[\"query\"], config)}\n",
        "\n",
        "\n",
        "# We then define logic that selects the prompt based on the classification\n",
        "def select_node(state: State) -> Literal[\"prompt_1\", \"prompt_2\"]:\n",
        "    if state[\"destination\"] == \"animal\":\n",
        "        return \"prompt_1\"\n",
        "    else:\n",
        "        return \"prompt_2\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpTTUXD2K1Zw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzgH1Hi0K0j_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfmWKf3IK1_I"
      },
      "source": [
        "This essentially builds a graph that handles the routing of the query to a particular chain in LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzvQm1DeHHMM"
      },
      "outputs": [],
      "source": [
        "# Finally, assemble the multi-prompt chain. This is a sequence of two steps:\n",
        "# 1) Select \"animal\" or \"vegetable\" via the route_chain, and collect the answer\n",
        "# alongside the input query.\n",
        "# 2) Route the input query to chain_1 or chain_2, based on the\n",
        "# selection.\n",
        "graph = StateGraph(State)\n",
        "graph.add_node(\"route_query\", route_query)\n",
        "graph.add_node(\"prompt_1\", prompt_1)\n",
        "graph.add_node(\"prompt_2\", prompt_2)\n",
        "\n",
        "graph.add_edge(START, \"route_query\")\n",
        "graph.add_conditional_edges(\"route_query\", select_node)\n",
        "graph.add_edge(\"prompt_1\", END)\n",
        "graph.add_edge(\"prompt_2\", END)\n",
        "app = graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "92ef8d86-daa6-4ff3-b722-468e7cf8bcb2",
        "outputId": "e88f48cd-8e04-4400-e3fc-a5bbd3444241"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(app.get_graph().draw_mermaid_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBBjguoaKYrD"
      },
      "source": [
        "You can try the previous queries below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61838f81-4e60-445f-9c05-563e3520ab33",
        "outputId": "505472b1-9423-4cdd-def7-2c2267d5839c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'destination': 'programming'}\n",
            "In Python, let’s make a class so fine,  \n",
            "To craft a directed graph, it will surely shine.  \n",
            "With a string of data, comma-separated,  \n",
            "We'll store the edges, all nicely fated.  \n",
            "\n",
            "```python\n",
            "class DirectedGraph:\n",
            "    def __init__(self, data_string):\n",
            "        self.graph = {}\n",
            "        # Split the string by commas, remove spaces too,  \n",
            "        edges = [pair.strip() for pair in data_string.split(',')]\n",
            "        for edge in edges:\n",
            "            if edge:  # Ensure it’s not an empty string\n",
            "                start, end = edge.split('->')  # Finding the arrow in between\n",
            "                if start not in self.graph:\n",
            "                    self.graph[start] = []\n",
            "                self.graph[start].append(end.strip())\n",
            "\n",
            "    def display(self):\n",
            "        for key, value in self.graph.items():\n",
            "            print(f\"{key} -> {', '.join(value)}\")\n",
            "\n",
            "# Example usage:\n",
            "data = \"A->B, A->C, B->D, C->D\"\n",
            "graph = DirectedGraph(data)\n",
            "graph.display() \n",
            "```\n",
            "\n",
            "In this code, we guide the flow,  \n",
            "From start to end, watch the edges grow.  \n",
            "With each connection, the graph will thrive,  \n",
            "Creating a structure where ideas can jive!\n"
          ]
        }
      ],
      "source": [
        "state = await app.ainvoke({\"query\": \"Can you develop a python class that creates a directed graph out of a comma separated string input\"})\n",
        "print(state[\"destination\"])\n",
        "print(state[\"answer\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7e46205-9d80-45b8-a3d5-cfbc8ebbe19a"
      },
      "source": [
        "In the [LangSmith trace](https://smith.langchain.com/public/1017a9d2-2d2a-4954-a5fd-5689632b4c5f/r) we can see the tool call that routed the query and the prompt that was selected to generate the answer.\n",
        "\n",
        "</details>\n",
        "\n",
        "## Overview:\n",
        "\n",
        "- Under the hood, `MultiPromptChain` routed the query by instructing the LLM to generate JSON-formatted text, and parses out the intended destination. It took a registry of string prompt templates as input.\n",
        "- The LangGraph implementation, implemented above via lower-level primitives, uses tool-calling to route to arbitrary chains. In this example, the chains include chat model templates and chat models."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
